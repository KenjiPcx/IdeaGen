{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import asyncpraw\n",
    "from datetime import datetime\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Your Reddit API credentials\n",
    "reddit_client_id = os.getenv(\"REDDIT_CLIENT_ID\")\n",
    "reddit_client_secret = os.getenv(\"REDDIT_CLIENT_SECRET\")\n",
    "reddit_user_agent = \"Ideagen\"\n",
    "\n",
    "# Your NVIDIA API key\n",
    "nvidia_api_key = os.getenv(\"NVIDIA_API_KEY\")\n",
    "\n",
    "# Subreddits to scrape\n",
    "subreddits = [\n",
    "    \"r/ecommerce\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrape_subreddit(reddit, subreddit_name, limit=10):\n",
    "    subreddit = await reddit.subreddit(subreddit_name.replace('r/', ''))\n",
    "    posts = []\n",
    "\n",
    "    async for submission in subreddit.hot(limit=limit):\n",
    "        posts.append({\n",
    "            'subreddit': subreddit_name,\n",
    "            'title': submission.title,\n",
    "            'body': submission.selftext,\n",
    "            'score': submission.score,\n",
    "            'url': submission.url,\n",
    "            'created': datetime.fromtimestamp(submission.created_utc).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        })\n",
    "\n",
    "    return posts\n",
    "\n",
    "async def scrape_reddit():\n",
    "    reddit = asyncpraw.Reddit(\n",
    "        client_id=reddit_client_id,\n",
    "        client_secret=reddit_client_secret,\n",
    "        user_agent=reddit_user_agent\n",
    "    )\n",
    "\n",
    "    all_posts = []\n",
    "    tasks = []\n",
    "\n",
    "    for subreddit in subreddits:\n",
    "        task = asyncio.create_task(scrape_subreddit(reddit, subreddit))\n",
    "        tasks.append(task)\n",
    "\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    for result in results:\n",
    "        all_posts.extend(result)\n",
    "\n",
    "    await reddit.close()\n",
    "    return all_posts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Extract pain points from posts\n",
    "\"\"\"\n",
    "class RedditPost(BaseModel):\n",
    "    subreddit: str\n",
    "    title: str\n",
    "    body: str\n",
    "    score: int\n",
    "    url: str\n",
    "    created: str\n",
    "    tags: List[str] = Field(default_factory=list)\n",
    "    pain_point: Optional[str] = Field(description=\"The problem encountered from the post\")\n",
    "    audience_affected: Optional[str] = Field(description=\"The audience affected by this problem\")\n",
    "    problem_why: Optional[str] = Field(description=\"Why the problem exists / root cause\")\n",
    "    cost_impact: Optional[str] = Field(description=\"Cost or impact of the problem (time, money)\")\n",
    "    detailed_examples: Optional[str] = Field(description=\"Detailed examples / user story (if possible)\")\n",
    "    stats_fact: Optional[str] = Field(description=\"Insightful facts about the problem / any insightful numbers or facts used in the post\")\n",
    "    combined_insights: Optional[str] = Field(description=\"A long analysis paragraph combining all points from pain point, audience, why it happens, its impact, its examples and stats\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_posts(posts):\n",
    "    filtered_posts = []\n",
    "    for post in posts:\n",
    "        content = f\"Title: {post['title']}\\n\\nBody: {post['body']}\"\n",
    "        \n",
    "        # Step 1: Classification prompt\n",
    "        classification_prompt = f\"\"\"Classify the following Reddit post into one or more of these categories: \n",
    "        [solution_request, pain_and_anger, money_talks, ideas, opportunities, advice_request], reply \"Yes\" if it does.\n",
    "        If the post doesn't fit any of these categories, respond with \"None\".\n",
    "\n",
    "        Post:\n",
    "        {content[:500]}\n",
    "\n",
    "        Classification:\"\"\"\n",
    "\n",
    "        classification = client.chat.completions.create(\n",
    "            # model=\"nvidia/llama-3.1-nemotron-70b-instruct\",\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": classification_prompt}],\n",
    "        )\n",
    "\n",
    "        tags = classification.choices[0].message.content.strip()\n",
    "\n",
    "        # If the post doesn't fit any category, skip it\n",
    "        if tags == \"None\":\n",
    "            continue\n",
    "\n",
    "        filtered_posts.append(post)\n",
    "    \n",
    "    return filtered_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import ValidationError\n",
    "\n",
    "\n",
    "def extract_pain_points(posts):\n",
    "    \n",
    "    refined_posts = []\n",
    "    for post in posts:\n",
    "        content = f\"Title: {post['title']}\\n\\nBody: {post['body']}\"\n",
    "        \n",
    "        analysis_prompt = f\"\"\"Analyze the following Reddit post and provide insights:\n",
    "\n",
    "        1. Tag the post with one or more of these tags: [solution_request, pain_and_anger, money_talks, ideas, opportunities, advice_request]\n",
    "        2. If the post discusses a business-related pain point, provide a high-level summary of the pain point in one sentence.\n",
    "        3. If a pain point is identified, provide detailed insights:\n",
    "           - Audience affected\n",
    "           - Why the problem exists / root cause\n",
    "           - Cost or impact of the problem (time, money)\n",
    "           - A user story describing the situation\n",
    "           - Detailed examples / user story (if possible)\n",
    "           - Relevant statistics (if possible)\n",
    "        4. Provide a combined paragraph that includes all the above insights in a coherent narrative.\n",
    "\n",
    "        Post:\n",
    "        {content}\n",
    "\n",
    "        Response format:\n",
    "        {RedditPost.model_json_schema()}\n",
    "        \n",
    "        Insights:\"\"\"\n",
    "\n",
    "        print(\"Calling model for \" + post[\"title\"])\n",
    "        completion = client.chat.completions.create(\n",
    "            # model=\"nvidia/llama-3.1-nemotron-70b-instruct\",\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": analysis_prompt}],\n",
    "        )\n",
    "\n",
    "        response = completion.choices[0].message.content.strip()\n",
    "        print(\"Got response\")\n",
    "\n",
    "        try:\n",
    "            # First, try to parse the response as JSON\n",
    "            response_dict = json.loads(response)\n",
    "        except json.JSONDecodeError:\n",
    "            # If it's not valid JSON, try to parse it manually\n",
    "            response_dict = {}\n",
    "            for line in response.split('\\n'):\n",
    "                if ':' in line:\n",
    "                    key, value = line.split(':', 1)\n",
    "                    response_dict[key.strip()] = value.strip()\n",
    "\n",
    "        # Add missing fields from the original post\n",
    "        response_dict['subreddit'] = post['subreddit']\n",
    "        response_dict['title'] = post['title']\n",
    "        response_dict['body'] = post['body']\n",
    "        response_dict['score'] = post['score']\n",
    "        response_dict['url'] = post['url']\n",
    "        response_dict['created'] = post['created']\n",
    "        \n",
    "        try:\n",
    "            refined_post = RedditPost(**response_dict)\n",
    "            print(\"Refined post\")\n",
    "        except ValidationError as e:\n",
    "            print(f\"Validation error: {e}\")\n",
    "            refined_post = None\n",
    "\n",
    "        refined_posts.append(refined_post)\n",
    "\n",
    "    return refined_posts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched posts\n",
      "Calling llms\n",
      "Filtered posts [{'subreddit': 'r/ecommerce', 'title': 'Now what?', 'body': 'Hey guys!\\n\\nI’m currently in China to visit the Canton Fair.\\nMy plan was to come here, visit the fair as well as the infamous Huaqiangbei electronic markets in Shenzhen and find a product to sell online.\\n\\nNow my problem is that I just found too many things. The selection of products that could potentially sell is so extremely huge that I’m in a kind of analysis paralysis. \\n\\nThere are a million different kinds of drones, smart watches, headphones, powerbanks, CPUs, GPUs… you name it. \\n\\nWhat would you do in such kind of a situation? \\nHow would you now choose the right product? Which filters would you use to come closer to a product that might be a good seller? ', 'score': 16, 'url': 'https://www.reddit.com/r/ecommerce/comments/1g8s891/now_what/', 'created': '2024-10-21 16:20:03'}, {'subreddit': 'r/ecommerce', 'title': 'Learn coding/html vs hiring web developers ', 'body': 'Wanted opinions about how some of you all manage your e-commerce businesses. Are the duties too much to learn or even phase out? ', 'score': 2, 'url': 'https://www.reddit.com/r/ecommerce/comments/1g95t1c/learn_codinghtml_vs_hiring_web_developers/', 'created': '2024-10-22 01:51:47'}, {'subreddit': 'r/ecommerce', 'title': 'Best Ecomm platform?', 'body': 'Currently company is looking at Ecomm solutions and are at the early stages of\\n\\nBigcommerce \\nShopify\\nCommercetools\\nSalesforce\\n\\nAny feedback or experiences is greatly appreciated\\n\\nSo far commercetools and Shopify seem like the front runners but I’d love outside input too. ', 'score': 2, 'url': 'https://www.reddit.com/r/ecommerce/comments/1g94xxn/best_ecomm_platform/', 'created': '2024-10-22 01:11:54'}, {'subreddit': 'r/ecommerce', 'title': 'Anyone have experience with For Good Profits?', 'body': 'I found them on Instagram and got their pitch. My product does super well in brick and mortar but I haven’t spent any time on the e-commerce side of things. We got our site redone and it looks gorgeous now. But I pretty much have no idea how to drive traffic to it. ', 'score': 2, 'url': 'https://www.reddit.com/r/ecommerce/comments/1g94vyl/anyone_have_experience_with_for_good_profits/', 'created': '2024-10-22 01:09:11'}, {'subreddit': 'r/ecommerce', 'title': 'Seeking Your Honest Feedback on My New Website!', 'body': \"Hey everyone! I just launched my website a week ago, and I’d love to hear your thoughts on it. I'm trying to gauge if there are areas I should improve or if I should stick with my current setup until I make my first sale. I've been running ads for the last three days at $10 a day, so I’m eager to see how things are shaping up. Any feedback or suggestions you can share would be greatly appreciated! \\n\\n  \\nThe link is there on my profile.\\n\\nThank you!\", 'score': 1, 'url': 'https://www.reddit.com/r/ecommerce/comments/1g970gu/seeking_your_honest_feedback_on_my_new_website/', 'created': '2024-10-22 02:54:03'}, {'subreddit': 'r/ecommerce', 'title': 'Looking for ERP Recommendations for $7M Shopify+ Business', 'body': 'Hey everyone,\\n\\nI’m looking for some advice on ERP systems and would love your recommendations!\\n\\nHere’s some context:\\n\\n* We’re running two brands on Shopify+ with around $7M in annual revenue.\\n* We sell on multiple platforms including Amazon (FBA & FBM), eBay, and Walmart.\\n* Roughly 20k orders annually\\n\\nWe’re trying to streamline our operations, especially inventory management and forecasting, while ideally integrating everything in one system.\\n\\nWhat ERP solutions are you using or would recommend for a business of our size? Any pros and cons you’ve experienced would be really helpful!\\n\\nThanks in advance!\\n\\nEDIT: Currently looking into BrightPearl.', 'score': 7, 'url': 'https://www.reddit.com/r/ecommerce/comments/1g8rz7b/looking_for_erp_recommendations_for_7m_shopify/', 'created': '2024-10-21 16:09:39'}, {'subreddit': 'r/ecommerce', 'title': 'Should I change my Ad content  between years?', 'body': 'Last year I ran ads through Facebook, they did pretty well. And I found some graphics that worked well. \\n\\nIs there any reason I can’t run the same exact ads again this year? Or should I change it up to something new?\\n\\nThanks,', 'score': 7, 'url': 'https://www.reddit.com/r/ecommerce/comments/1g8qpcz/should_i_change_my_ad_content_between_years/', 'created': '2024-10-21 15:14:35'}, {'subreddit': 'r/ecommerce', 'title': 'Google Merchant Center - Add Ship From Address only offering France, Germany, and USA as countries to ship from, but we ship from Canada. Any Idea how to fix it?', 'body': 'We are based in Canada and the address in the merchant account is the same address as our ship from. \\n\\nGoogle has been no help and has not gotten back to us about this issue. \\n\\nOn this [webpage](https://merchants.google.com/mc/shipping/) we tried to add the **ship from address** but it only shows Germany, France, and the USA as country options. I tried a lot of different ways to enter the address, no success, thus no shipping address.   \\n  \\nAs a result the store is being limited on google. Ugh.  ', 'score': 2, 'url': 'https://www.reddit.com/r/ecommerce/comments/1g8yfz3/google_merchant_center_add_ship_from_address_only/', 'created': '2024-10-21 20:29:49'}, {'subreddit': 'r/ecommerce', 'title': 'Video ad creative sourcing ', 'body': 'Hey guys, \\n\\nI’m curious to know what agencies or services you’ve used that create quality video ads. I’m primarily advertising on meta. ', 'score': 2, 'url': 'https://www.reddit.com/r/ecommerce/comments/1g8x6qg/video_ad_creative_sourcing/', 'created': '2024-10-21 19:39:14'}]\n",
      "[{'subreddit': 'r/ecommerce', 'title': 'Now what?', 'body': 'Hey guys!\\n\\nI’m currently in China to visit the Canton Fair.\\nMy plan was to come here, visit the fair as well as the infamous Huaqiangbei electronic markets in Shenzhen and find a product to sell online.\\n\\nNow my problem is that I just found too many things. The selection of products that could potentially sell is so extremely huge that I’m in a kind of analysis paralysis. \\n\\nThere are a million different kinds of drones, smart watches, headphones, powerbanks, CPUs, GPUs… you name it. \\n\\nWhat would you do in such kind of a situation? \\nHow would you now choose the right product? Which filters would you use to come closer to a product that might be a good seller? ', 'score': 16, 'url': 'https://www.reddit.com/r/ecommerce/comments/1g8s891/now_what/', 'created': '2024-10-21 16:20:03'}, {'subreddit': 'r/ecommerce', 'title': 'Learn coding/html vs hiring web developers ', 'body': 'Wanted opinions about how some of you all manage your e-commerce businesses. Are the duties too much to learn or even phase out? ', 'score': 2, 'url': 'https://www.reddit.com/r/ecommerce/comments/1g95t1c/learn_codinghtml_vs_hiring_web_developers/', 'created': '2024-10-22 01:51:47'}, {'subreddit': 'r/ecommerce', 'title': 'Best Ecomm platform?', 'body': 'Currently company is looking at Ecomm solutions and are at the early stages of\\n\\nBigcommerce \\nShopify\\nCommercetools\\nSalesforce\\n\\nAny feedback or experiences is greatly appreciated\\n\\nSo far commercetools and Shopify seem like the front runners but I’d love outside input too. ', 'score': 2, 'url': 'https://www.reddit.com/r/ecommerce/comments/1g94xxn/best_ecomm_platform/', 'created': '2024-10-22 01:11:54'}, {'subreddit': 'r/ecommerce', 'title': 'Anyone have experience with For Good Profits?', 'body': 'I found them on Instagram and got their pitch. My product does super well in brick and mortar but I haven’t spent any time on the e-commerce side of things. We got our site redone and it looks gorgeous now. But I pretty much have no idea how to drive traffic to it. ', 'score': 2, 'url': 'https://www.reddit.com/r/ecommerce/comments/1g94vyl/anyone_have_experience_with_for_good_profits/', 'created': '2024-10-22 01:09:11'}, {'subreddit': 'r/ecommerce', 'title': 'Seeking Your Honest Feedback on My New Website!', 'body': \"Hey everyone! I just launched my website a week ago, and I’d love to hear your thoughts on it. I'm trying to gauge if there are areas I should improve or if I should stick with my current setup until I make my first sale. I've been running ads for the last three days at $10 a day, so I’m eager to see how things are shaping up. Any feedback or suggestions you can share would be greatly appreciated! \\n\\n  \\nThe link is there on my profile.\\n\\nThank you!\", 'score': 1, 'url': 'https://www.reddit.com/r/ecommerce/comments/1g970gu/seeking_your_honest_feedback_on_my_new_website/', 'created': '2024-10-22 02:54:03'}, {'subreddit': 'r/ecommerce', 'title': 'Looking for ERP Recommendations for $7M Shopify+ Business', 'body': 'Hey everyone,\\n\\nI’m looking for some advice on ERP systems and would love your recommendations!\\n\\nHere’s some context:\\n\\n* We’re running two brands on Shopify+ with around $7M in annual revenue.\\n* We sell on multiple platforms including Amazon (FBA & FBM), eBay, and Walmart.\\n* Roughly 20k orders annually\\n\\nWe’re trying to streamline our operations, especially inventory management and forecasting, while ideally integrating everything in one system.\\n\\nWhat ERP solutions are you using or would recommend for a business of our size? Any pros and cons you’ve experienced would be really helpful!\\n\\nThanks in advance!\\n\\nEDIT: Currently looking into BrightPearl.', 'score': 7, 'url': 'https://www.reddit.com/r/ecommerce/comments/1g8rz7b/looking_for_erp_recommendations_for_7m_shopify/', 'created': '2024-10-21 16:09:39'}, {'subreddit': 'r/ecommerce', 'title': 'Should I change my Ad content  between years?', 'body': 'Last year I ran ads through Facebook, they did pretty well. And I found some graphics that worked well. \\n\\nIs there any reason I can’t run the same exact ads again this year? Or should I change it up to something new?\\n\\nThanks,', 'score': 7, 'url': 'https://www.reddit.com/r/ecommerce/comments/1g8qpcz/should_i_change_my_ad_content_between_years/', 'created': '2024-10-21 15:14:35'}, {'subreddit': 'r/ecommerce', 'title': 'Google Merchant Center - Add Ship From Address only offering France, Germany, and USA as countries to ship from, but we ship from Canada. Any Idea how to fix it?', 'body': 'We are based in Canada and the address in the merchant account is the same address as our ship from. \\n\\nGoogle has been no help and has not gotten back to us about this issue. \\n\\nOn this [webpage](https://merchants.google.com/mc/shipping/) we tried to add the **ship from address** but it only shows Germany, France, and the USA as country options. I tried a lot of different ways to enter the address, no success, thus no shipping address.   \\n  \\nAs a result the store is being limited on google. Ugh.  ', 'score': 2, 'url': 'https://www.reddit.com/r/ecommerce/comments/1g8yfz3/google_merchant_center_add_ship_from_address_only/', 'created': '2024-10-21 20:29:49'}, {'subreddit': 'r/ecommerce', 'title': 'Video ad creative sourcing ', 'body': 'Hey guys, \\n\\nI’m curious to know what agencies or services you’ve used that create quality video ads. I’m primarily advertising on meta. ', 'score': 2, 'url': 'https://www.reddit.com/r/ecommerce/comments/1g8x6qg/video_ad_creative_sourcing/', 'created': '2024-10-21 19:39:14'}]\n"
     ]
    }
   ],
   "source": [
    "posts = await scrape_reddit()\n",
    "print(\"Fetched posts\")\n",
    "print(\"Calling llms\")\n",
    "posts = filter_posts(posts)\n",
    "print(\"Filtered posts\", posts)\n",
    "post = posts[:3]\n",
    "print(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling model for Now what?\n",
      "Got response\n",
      "Validation error: 7 validation errors for RedditPost\n",
      "pain_point\n",
      "  Field required [type=missing, input_value={'\"properties\"': '{', '\"s...: '2024-10-21 16:20:03'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.9/v/missing\n",
      "audience_affected\n",
      "  Field required [type=missing, input_value={'\"properties\"': '{', '\"s...: '2024-10-21 16:20:03'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.9/v/missing\n",
      "problem_why\n",
      "  Field required [type=missing, input_value={'\"properties\"': '{', '\"s...: '2024-10-21 16:20:03'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.9/v/missing\n",
      "cost_impact\n",
      "  Field required [type=missing, input_value={'\"properties\"': '{', '\"s...: '2024-10-21 16:20:03'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.9/v/missing\n",
      "detailed_examples\n",
      "  Field required [type=missing, input_value={'\"properties\"': '{', '\"s...: '2024-10-21 16:20:03'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.9/v/missing\n",
      "stats_fact\n",
      "  Field required [type=missing, input_value={'\"properties\"': '{', '\"s...: '2024-10-21 16:20:03'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.9/v/missing\n",
      "combined_insights\n",
      "  Field required [type=missing, input_value={'\"properties\"': '{', '\"s...: '2024-10-21 16:20:03'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.9/v/missing\n",
      "Calling model for Learn coding/html vs hiring web developers \n",
      "Got response\n",
      "Validation error: 7 validation errors for RedditPost\n",
      "pain_point\n",
      "  Field required [type=missing, input_value={'\"subreddit\"': '\"busines...: '2024-10-22 01:51:47'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.9/v/missing\n",
      "audience_affected\n",
      "  Field required [type=missing, input_value={'\"subreddit\"': '\"busines...: '2024-10-22 01:51:47'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.9/v/missing\n",
      "problem_why\n",
      "  Field required [type=missing, input_value={'\"subreddit\"': '\"busines...: '2024-10-22 01:51:47'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.9/v/missing\n",
      "cost_impact\n",
      "  Field required [type=missing, input_value={'\"subreddit\"': '\"busines...: '2024-10-22 01:51:47'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.9/v/missing\n",
      "detailed_examples\n",
      "  Field required [type=missing, input_value={'\"subreddit\"': '\"busines...: '2024-10-22 01:51:47'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.9/v/missing\n",
      "stats_fact\n",
      "  Field required [type=missing, input_value={'\"subreddit\"': '\"busines...: '2024-10-22 01:51:47'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.9/v/missing\n",
      "combined_insights\n",
      "  Field required [type=missing, input_value={'\"subreddit\"': '\"busines...: '2024-10-22 01:51:47'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.9/v/missing\n",
      "Calling model for Best Ecomm platform?\n",
      "Got response\n",
      "Validation error: 7 validation errors for RedditPost\n",
      "pain_point\n",
      "  Field required [type=missing, input_value={'\"properties\"': '{', '\"s...: '2024-10-22 01:11:54'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.9/v/missing\n",
      "audience_affected\n",
      "  Field required [type=missing, input_value={'\"properties\"': '{', '\"s...: '2024-10-22 01:11:54'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.9/v/missing\n",
      "problem_why\n",
      "  Field required [type=missing, input_value={'\"properties\"': '{', '\"s...: '2024-10-22 01:11:54'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.9/v/missing\n",
      "cost_impact\n",
      "  Field required [type=missing, input_value={'\"properties\"': '{', '\"s...: '2024-10-22 01:11:54'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.9/v/missing\n",
      "detailed_examples\n",
      "  Field required [type=missing, input_value={'\"properties\"': '{', '\"s...: '2024-10-22 01:11:54'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.9/v/missing\n",
      "stats_fact\n",
      "  Field required [type=missing, input_value={'\"properties\"': '{', '\"s...: '2024-10-22 01:11:54'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.9/v/missing\n",
      "combined_insights\n",
      "  Field required [type=missing, input_value={'\"properties\"': '{', '\"s...: '2024-10-22 01:11:54'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.9/v/missing\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object list can't be used in 'await' expression",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m extract_pain_points(post)\n\u001b[1;32m      2\u001b[0m res\n",
      "\u001b[0;31mTypeError\u001b[0m: object list can't be used in 'await' expression"
     ]
    }
   ],
   "source": [
    "res = await extract_pain_points(post)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cluster_pain_points(pain_points):\n",
    "    client = OpenAI(\n",
    "        base_url=\"https://integrate.api.nvidia.com/v1\",\n",
    "        api_key=nvidia_api_key\n",
    "    )\n",
    "\n",
    "    pain_point_list = \"\\n\".join([f\"- {p['pain_point']}\" for p in pain_points])\n",
    "    \n",
    "    prompt = f\"\"\"Given the following list of business pain points, cluster them into 5-7 groups based on similarity. \n",
    "    Provide a label for each cluster and list the pain points that belong to it.\n",
    "\n",
    "    Pain points:\n",
    "    {pain_point_list}\n",
    "\n",
    "    Clustered results:\"\"\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"nvidia/llama-3.1-nemotron-70b-instruct\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.5,\n",
    "        max_tokens=1000\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_report(clustered_results, pain_points):\n",
    "    client = OpenAI(\n",
    "        base_url=\"https://integrate.api.nvidia.com/v1\",\n",
    "        api_key=nvidia_api_key\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"Based on the following clustered results of business pain points, generate a comprehensive market research report. \n",
    "    For each cluster, provide:\n",
    "    1. A summary of the main issue\n",
    "    2. Potential business opportunities addressing this pain point\n",
    "    3. Recommendations for further investigation\n",
    "\n",
    "    Clustered results:\n",
    "    {clustered_results}\n",
    "\n",
    "    Market Research Report:\"\"\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"nvidia/llama-3.1-nemotron-70b-instruct\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.7,\n",
    "        max_tokens=2000\n",
    "    )\n",
    "\n",
    "    report = completion.choices[0].message.content.strip()\n",
    "\n",
    "    # Add links to original posts\n",
    "    for cluster in clustered_results.split(\"\\n\\n\"):\n",
    "        cluster_name = cluster.split(\"\\n\")[0]\n",
    "        report += f\"\\n\\nRelevant posts for {cluster_name}:\\n\"\n",
    "        for pain_point in pain_points:\n",
    "            if pain_point['pain_point'] in cluster:\n",
    "                report += f\"- [{pain_point['pain_point']}]({pain_point['url']}) (Score: {pain_point['score']})\\n\"\n",
    "\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    # Scrape Reddit\n",
    "    posts = await scrape_reddit()\n",
    "    print(f\"Scraped {len(posts)} posts from Reddit\")\n",
    "\n",
    "    # Extract pain points\n",
    "    pain_points = extract_pain_points(posts)\n",
    "    print(f\"Extracted {len(pain_points)} pain points\")\n",
    "\n",
    "    # Cluster pain points\n",
    "    clustered_results = cluster_pain_points(pain_points)\n",
    "    print(\"Clustered pain points\")\n",
    "\n",
    "    # Generate report\n",
    "    report = generate_report(clustered_results, pain_points)\n",
    "    print(\"Generated market research report\")\n",
    "\n",
    "    # Save report to file\n",
    "    with open(\"market_research_report.md\", \"w\") as f:\n",
    "        f.write(report)\n",
    "\n",
    "    print(\"Report saved to market_research_report.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped 40 posts from Reddit\n",
      "Extracted 40 pain points\n",
      "Clustered pain points\n",
      "Generated market research report\n",
      "Report saved to market_research_report.md\n"
     ]
    }
   ],
   "source": [
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ideagen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
